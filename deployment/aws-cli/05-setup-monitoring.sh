#!/bin/bash
# 05-setup-monitoring.sh
# é…ç½®ç›‘æ§ã€æ—¥å¿—å’Œå‘Šè­¦

set -e

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m'

echo -e "${BLUE}ğŸ“Š é…ç½®ç›‘æ§å’Œæ—¥å¿—ç³»ç»Ÿ...${NC}"

# æ£€æŸ¥é›†ç¾¤è¿æ¥
if ! kubectl cluster-info &>/dev/null; then
    echo -e "${RED}âŒ æ— æ³•è¿æ¥åˆ° K8s é›†ç¾¤${NC}"
    exit 1
fi

# 1. å®‰è£… Prometheus Operator
echo -e "\n${YELLOW}ğŸ“ˆ å®‰è£… Prometheus ç›‘æ§...${NC}"

# æ·»åŠ  Prometheus ç¤¾åŒº Helm repo
if ! helm repo list | grep prometheus-community &>/dev/null; then
    echo "æ·»åŠ  Prometheus Helm repository..."
    helm repo add prometheus-community https://prometheus-community.github.io/helm-charts
fi

helm repo update

# åˆ›å»ºç›‘æ§å‘½åç©ºé—´
kubectl create namespace monitoring --dry-run=client -o yaml | kubectl apply -f -

# å®‰è£… kube-prometheus-stack
if ! helm list -n monitoring | grep kube-prometheus-stack &>/dev/null; then
    echo "å®‰è£… kube-prometheus-stack..."
    
    # åˆ›å»º values é…ç½®
    cat > prometheus-values.yaml <<EOF
grafana:
  enabled: true
  adminPassword: "kortix-admin-2024"
  service:
    type: LoadBalancer
  persistence:
    enabled: true
    size: 10Gi
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
      - name: 'default'
        orgId: 1
        folder: ''
        type: file
        disableDeletion: false
        editable: true
        options:
          path: /var/lib/grafana/dashboards/default

prometheus:
  prometheusSpec:
    storageSpec:
      volumeClaimTemplate:
        spec:
          storageClassName: gp3
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 20Gi
    retention: 7d
    resources:
      requests:
        memory: "2Gi"
        cpu: "500m"
      limits:
        memory: "4Gi" 
        cpu: "1000m"

alertmanager:
  alertmanagerSpec:
    storage:
      volumeClaimTemplate:
        spec:
          storageClassName: gp3
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 10Gi

nodeExporter:
  enabled: true

kubeStateMetrics:
  enabled: true
EOF
    
    helm install kube-prometheus-stack prometheus-community/kube-prometheus-stack \
        --namespace monitoring \
        --values prometheus-values.yaml \
        --wait
        
    rm -f prometheus-values.yaml
else
    echo "kube-prometheus-stack å·²å®‰è£…"
fi

# 2. é…ç½®åº”ç”¨æŒ‡æ ‡æ”¶é›†
echo -e "\n${YELLOW}ğŸ” é…ç½®åº”ç”¨ç›‘æ§...${NC}"

# åˆ›å»º ServiceMonitor æ¥æ”¶é›†åº”ç”¨æŒ‡æ ‡
kubectl apply -f - <<EOF
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor
metadata:
  name: backend-api-metrics
  namespace: monitoring
  labels:
    app: backend-api
spec:
  selector:
    matchLabels:
      app: backend-api
  namespaceSelector:
    matchNames:
    - kortix-backend
  endpoints:
  - port: http
    path: /metrics
    interval: 30s
---
apiVersion: monitoring.coreos.com/v1
kind: ServiceMonitor  
metadata:
  name: redis-metrics
  namespace: monitoring
  labels:
    app: redis
spec:
  selector:
    matchLabels:
      app: redis
  namespaceSelector:
    matchNames:
    - kortix-backend
  endpoints:
  - port: redis
    interval: 30s
EOF

# 3. å®‰è£…æ—¥å¿—æ”¶é›† (Loki + Promtail)
echo -e "\n${YELLOW}ğŸ“‹ å®‰è£…æ—¥å¿—æ”¶é›†ç³»ç»Ÿ...${NC}"

# æ·»åŠ  Grafana Helm repo
if ! helm repo list | grep grafana &>/dev/null; then
    helm repo add grafana https://grafana.github.io/helm-charts
    helm repo update
fi

# å®‰è£… Loki
if ! helm list -n monitoring | grep loki &>/dev/null; then
    echo "å®‰è£… Loki..."
    helm install loki grafana/loki-stack \
        --namespace monitoring \
        --set loki.persistence.enabled=true \
        --set loki.persistence.size=20Gi \
        --set loki.persistence.storageClassName=gp3 \
        --wait
else
    echo "Loki å·²å®‰è£…"
fi

# 4. åˆ›å»ºè‡ªå®šä¹‰ Dashboard
echo -e "\n${YELLOW}ğŸ“Š åˆ›å»º Kortix Dashboard...${NC}"

# åˆ›å»º ConfigMap åŒ…å« Dashboard JSON
kubectl apply -f - <<EOF
apiVersion: v1
kind: ConfigMap
metadata:
  name: kortix-dashboard
  namespace: monitoring
  labels:
    grafana_dashboard: "1"
data:
  kortix-dashboard.json: |
    {
      "dashboard": {
        "id": null,
        "title": "Kortix Application Monitoring",
        "tags": ["kortix", "api", "backend"],
        "timezone": "browser",
        "panels": [
          {
            "id": 1,
            "title": "API Request Rate",
            "type": "graph",
            "targets": [
              {
                "expr": "sum(rate(http_requests_total{job=\"backend-api\"}[5m]))",
                "legendFormat": "Requests/sec"
              }
            ],
            "yAxes": [{"label": "req/sec"}],
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 0}
          },
          {
            "id": 2,
            "title": "API Response Time",
            "type": "graph", 
            "targets": [
              {
                "expr": "histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{job=\"backend-api\"}[5m])) by (le))",
                "legendFormat": "95th percentile"
              }
            ],
            "yAxes": [{"label": "seconds"}],
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 0}
          },
          {
            "id": 3,
            "title": "Pod CPU Usage",
            "type": "graph",
            "targets": [
              {
                "expr": "sum(rate(container_cpu_usage_seconds_total{namespace=\"kortix-backend\"}[5m])) by (pod)",
                "legendFormat": "{{pod}}"
              }
            ],
            "gridPos": {"h": 8, "w": 12, "x": 0, "y": 8}
          },
          {
            "id": 4,
            "title": "Pod Memory Usage",
            "type": "graph",
            "targets": [
              {
                "expr": "sum(container_memory_usage_bytes{namespace=\"kortix-backend\"}) by (pod)",
                "legendFormat": "{{pod}}"
              }
            ],
            "gridPos": {"h": 8, "w": 12, "x": 12, "y": 8}
          }
        ],
        "time": {"from": "now-1h", "to": "now"},
        "refresh": "5s"
      }
    }
EOF

# 5. é…ç½®å‘Šè­¦è§„åˆ™
echo -e "\n${YELLOW}ğŸš¨ é…ç½®å‘Šè­¦è§„åˆ™...${NC}"

kubectl apply -f - <<EOF
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: kortix-alerts
  namespace: monitoring
  labels:
    app: kube-prometheus-stack
    release: kube-prometheus-stack
spec:
  groups:
  - name: kortix.rules
    rules:
    - alert: KortixAPIDown
      expr: up{job="backend-api"} == 0
      for: 1m
      labels:
        severity: critical
      annotations:
        summary: "Kortix API is down"
        description: "Backend API has been down for more than 1 minute"
        
    - alert: KortixHighLatency
      expr: histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{job="backend-api"}[5m])) by (le)) > 1
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "Kortix API high latency"
        description: "API 95th percentile latency is above 1 second"
        
    - alert: KortixHighCPU
      expr: sum(rate(container_cpu_usage_seconds_total{namespace="kortix-backend"}[5m])) by (pod) > 0.8
      for: 10m
      labels:
        severity: warning
      annotations:
        summary: "Kortix pod high CPU usage"
        description: "Pod {{$labels.pod}} CPU usage is above 80%"
        
    - alert: KortixHighMemory
      expr: sum(container_memory_usage_bytes{namespace="kortix-backend"}) by (pod) / sum(container_spec_memory_limit_bytes{namespace="kortix-backend"}) by (pod) > 0.9
      for: 10m
      labels:
        severity: critical
      annotations:
        summary: "Kortix pod high memory usage"
        description: "Pod {{$labels.pod}} memory usage is above 90%"
        
    - alert: KortixRedisDown
      expr: up{job="redis"} == 0
      for: 1m
      labels:
        severity: critical
      annotations:
        summary: "Redis is down"
        description: "Redis has been down for more than 1 minute"
EOF

# 6. ç­‰å¾…æœåŠ¡å¯åŠ¨å¹¶è·å–è®¿é—®ä¿¡æ¯
echo -e "\n${YELLOW}â³ ç­‰å¾…ç›‘æ§æœåŠ¡å¯åŠ¨...${NC}"

kubectl wait --for=condition=ready --timeout=300s pod -l app.kubernetes.io/name=grafana -n monitoring

# è·å– Grafana è®¿é—®ä¿¡æ¯
GRAFANA_LB=$(kubectl get service kube-prometheus-stack-grafana -n monitoring -o jsonpath='{.status.loadBalancer.ingress[0].hostname}')

echo -e "\n${GREEN}ğŸ‰ ç›‘æ§ç³»ç»Ÿé…ç½®å®Œæˆï¼${NC}"
echo "=================================="
echo "Grafana è®¿é—®ä¿¡æ¯ï¼š"
if [ ! -z "$GRAFANA_LB" ]; then
    echo "URL: http://$GRAFANA_LB"
    echo "ç”¨æˆ·å: admin"
    echo "å¯†ç : kortix-admin-2024"
else
    echo "Grafana LoadBalancer æ­£åœ¨åˆ›å»ºä¸­..."
    echo "è¯·ç¨ç­‰å‡ åˆ†é’Ÿåè¿è¡Œï¼š"
    echo "kubectl get service kube-prometheus-stack-grafana -n monitoring"
fi

echo -e "\nå…¶ä»–ç›‘æ§ç»„ä»¶ï¼š"
echo "Prometheus: http://$GRAFANA_LB:9090"
echo "AlertManager: http://$GRAFANA_LB:9093"

# ä¿å­˜ç›‘æ§ä¿¡æ¯
cat > monitoring-info.txt <<EOF
Kortix ç›‘æ§ç³»ç»Ÿè®¿é—®ä¿¡æ¯
=======================

Grafana Dashboard:
URL: http://$GRAFANA_LB
Username: admin
Password: kortix-admin-2024

é¢„ç½® Dashboardï¼š
- Kubernetes Cluster Monitoring
- Node Exporter
- Kortix Application Monitoring (è‡ªå®šä¹‰)

æœ‰ç”¨çš„ Prometheus æŸ¥è¯¢ï¼š
# API è¯·æ±‚ç‡
sum(rate(http_requests_total{job="backend-api"}[5m]))

# API å»¶è¿Ÿ P95
histogram_quantile(0.95, sum(rate(http_request_duration_seconds_bucket{job="backend-api"}[5m])) by (le))

# Pod CPU ä½¿ç”¨ç‡
sum(rate(container_cpu_usage_seconds_total{namespace="kortix-backend"}[5m])) by (pod)

# Pod å†…å­˜ä½¿ç”¨é‡
sum(container_memory_usage_bytes{namespace="kortix-backend"}) by (pod)

ç®¡ç†å‘½ä»¤ï¼š
# æŸ¥çœ‹ç›‘æ§ Pod
kubectl get pods -n monitoring

# é‡å¯ Grafana
kubectl rollout restart deployment/kube-prometheus-stack-grafana -n monitoring

# æŸ¥çœ‹å‘Šè­¦è§„åˆ™
kubectl get prometheusrules -n monitoring

# æŸ¥çœ‹ ServiceMonitor
kubectl get servicemonitors -n monitoring
EOF

echo -e "\n${GREEN}ğŸ“„ ç›‘æ§ä¿¡æ¯å·²ä¿å­˜åˆ° monitoring-info.txt${NC}"

# éªŒè¯å‘Šè­¦è§„åˆ™
echo -e "\n${BLUE}ğŸ” éªŒè¯é…ç½®...${NC}"
echo "=== PrometheusRules ==="
kubectl get prometheusrules -n monitoring

echo -e "\n=== ServiceMonitors ==="
kubectl get servicemonitors -n monitoring

echo -e "\n=== Monitoring Pods ==="
kubectl get pods -n monitoring

echo -e "\n${GREEN}âœ… ç›‘æ§ç³»ç»Ÿé…ç½®å®Œæˆï¼${NC}"
echo "ç°åœ¨å¯ä»¥é€šè¿‡ Grafana æŸ¥çœ‹åº”ç”¨ç›‘æ§æ•°æ®"